{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Workflow"
      ],
      "metadata": {
        "id": "8uCROBPCsdVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering = {\n",
        "    1: \"Data (prepare and load)\",\n",
        "    2: \"Build model\",\n",
        "    3: \"Fitting the model to data (training)\",\n",
        "    4: \"Maing predictions and evaluating a model (inference)\",\n",
        "    5: \"Saving and loading the model\",\n",
        "    6: \"Putting it all together\"\n",
        "    }\n",
        "what_were_covering"
      ],
      "metadata": {
        "id": "k-VDlwC-s_wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn -> https://pytorch.org/docs/stable/nn.html"
      ],
      "metadata": {
        "id": "3NMxqr8xtzcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "9XfyLFa-thqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data (Preparing and loading)\n",
        "\n",
        "Data can almost be anything... in maching learning/\n",
        "\n",
        "* Excel\n",
        "* Images of any ing\n",
        "* Videos\n",
        "* Audio like songs and podcasta\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Maching learning is mainly divides into 2 parts:\n",
        "1. Get data into a numerical representation.\n",
        "2. Build a model to learn patterns in theat numerical representation.\n",
        "\n",
        "To showcase this, Let's create some **known** data using the linear regressing formula.\n",
        "\n",
        "We'll use a linear regressiong formula to make a straight line with know `parameters`."
      ],
      "metadata": {
        "id": "fwruLHGXuq0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create data\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "x = torch.arange(start,end,step).unsqueeze(dim=1)\n",
        "y = weight * x + bias\n",
        "\n",
        "x[:10], y[:10],x.shape,y.shape"
      ],
      "metadata": {
        "id": "aWDOQOequ9Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x),len(y)"
      ],
      "metadata": {
        "id": "_TpdbQi-woR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets\n",
        "\n",
        "`Goal` -> **Generalization**: The ability for a maching learning model to perform well on data it hasn't seen before"
      ],
      "metadata": {
        "id": "vWH3MOLIwrGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a train/test split\n",
        "train_split = int(0.8*len(x))\n",
        "x_train,y_train = x[:train_split],y[:train_split]\n",
        "x_test,y_test = x[train_split:],y[train_split:]\n",
        "len(x_train),len(y_train),len(x_test),len(y_test)"
      ],
      "metadata": {
        "id": "DN-R9ZX4xmys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing data"
      ],
      "metadata": {
        "id": "8jmuJ1ItziaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=x_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=x_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots traing data,test data and compares predictions\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  # Plot traing data in blue\n",
        "  plt.scatter(train_data,train_labels,c=\"b\",s=4,label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data,test_labels,c=\"g\",s=4,label=\"Test data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # plot predictions if they exist\n",
        "    plt.scatter(test_data,predictions, c=\"r\",s=4,label=\"Predictions\")\n",
        "\n",
        "  # Show legend\n",
        "  plt.legend(prop={\"size\":14});"
      ],
      "metadata": {
        "id": "796yeUXHygLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "id": "yUgyVY7UzaOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2. Build a model\n",
        "\n",
        " What our model does:\n",
        " * Start with random values (weights, bias)\n",
        " * Look at the training data and adjust the random values to better represent the ideal values\n",
        "\n",
        "How does it do so?\n",
        "Through two main algorithms:\n",
        "1. Gradient descent\n",
        "2. Backward propogation\n",
        "\n",
        "(watch 3b1b for both)"
      ],
      "metadata": {
        "id": "eaGU44Zz1I9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use this only for simple models for understanding, for example with data from images, these parameters are defined by another module in nn.Module for us.\n",
        "# Create a linear regressiong model class\n",
        "class LinearRegressionModel(nn.Module): # <-almost everything in PyTorch inherits from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, # start with a random weight to try to adjust it to the ideal weights\n",
        "                                            requires_grad=True, #True by default, means PyTorch will track the gradients of this specific parameter for use with torch.autograd and gradient descent\n",
        "                                            dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                         requires_grad=True,\n",
        "                                         dtype=float))\n",
        "\n",
        "  # Forward method to define the computation in the model\n",
        "  def forward(self,x :torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
        "    return self.weights * x + self.bias # linear regression formula\n",
        "\n"
      ],
      "metadata": {
        "id": "Rfu8mNMu2Hr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all of the building blocks for computational graphs (a neural network can be considerd a computational graph)\n",
        "* torch.nn.Parameter - what parameters should our model try and learn, often a Pytorch layer from torch.nn will set these for us\n",
        "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
        "* torch.optim - This is where the optimizer algorithm in PyTorch are stored, they help wiht gradient descent\n",
        "* def forward() - All nn.module subclass require you to overwrite forward(), this method defines what happens is forward computation\n"
      ],
      "metadata": {
        "id": "7X29mcpD5tar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "Now we've created a model, let's see what's inside...\n",
        "\n",
        "We can check our model parameters or what's inside our model using `.parameters()`."
      ],
      "metadata": {
        "id": "PTNTcUrA-02Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "zKyf5Otc_0ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "x7zP3wW1AFfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making prediction using `torch.inference_mode()`\n",
        "\n",
        "To check our model's predictive power, Let's see how well it predicts `y_test` base on `x_test`\n",
        "\n",
        "When we pass data through our model, it's going to run it through the `forward()` method"
      ],
      "metadata": {
        "id": "WGRK8mdaB3GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction with model\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(x_test)\n",
        "\n",
        "# You can also do something with torch.no_grad(), however, torch.inference_mode() is preferred\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(x_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "CelJu6pECVXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "OsVeh48qDQEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "id": "OcYlqtwTEMWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train model\n",
        "\n",
        "The whole idea of training is for a model to move from a *unknown* parameter (these may be random) to some *known* parameter.\n",
        "\n",
        "In other words from a poor representation of the data to a better representation of th data.\n",
        "\n",
        "One way to measure how poor or how wrong your model predictions are is to use a loss function.\n",
        "\n",
        "* Note: Loss function may also be called cost function or criterion in different areas.\n",
        "\n",
        "Things we need to train:\n",
        "\n",
        "* **Loss function:** A function to measure how wrong your model's predictions are to the ideal output, lower is better.\n",
        "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (eg: weights & bias) to imporve the loss function.\n",
        "  * inside optimizer we set two parameters:\n",
        "    * `params` - the model parameters you'd like to optimize, for example `params=model_0.parameters()`\n",
        "    * `lr` (learning rate) - the learning rate is a hyperparameter that defines how big/small the optimizer changes the parameters with each step( a samll `lr` results in a small change, large `lr` results in large changes)\n",
        "      \n",
        "\n",
        "And specifically for PyTorch, we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "WHrmhIjgER0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "Uu-8k_Fcg3ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "SkGHUCHDg3eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss() # L1Loss - MAE (mean absolute error)\n",
        "\n",
        "# Setup an optimizer, SDG-(stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.01,) # Larger the learning rate, larger the change in parameter"
      ],
      "metadata": {
        "id": "Ia8tQvWZej32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a training loop and testing loop in PyTorch\n",
        "\n",
        "A couple of thing we need in training loop:\n",
        "0. Loop through the data and do...\n",
        "1. Forward pass (this involves data moving though our model's `forward()` functions) to make predictions on data - also called forward propogation\n",
        "2. Calculate the loss (compare forward pass predictions to  ground truth label)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (***backpropogation***)\n",
        "5. Optimizer step - use the optimizer to adjust the model's parameters to try to imporve the loss. (**Gradient descent**)"
      ],
      "metadata": {
        "id": "_mKUbgzPh2CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch is one loop through the data\n",
        "epochs = 200\n",
        "\n",
        "# Tracking different values\n",
        "epoch_count=[]\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "\n",
        "### Training\n",
        "# 0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in PyTorch sets all parameters that requires gradients to require gradients.\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_preds = model_0(x_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_preds,y_train)\n",
        "  # print(f\"Loss: {loss}\")\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropogation on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Steop the Optimizer (perform gradient descent)\n",
        "  optimizer.step()  # By default how the optimizer changes will accumulate through the loop so we have to zero them above in step 3 for the next iteration of the loop\n",
        "\n",
        "  # Testing\n",
        "  model_0.eval()  # turns off different settings in the model not needed for evaluating/testing (dropout, batch norm layers)\n",
        "  with torch.inference_mode(): #turns off gradient tracking & a couple morethings behind the scenes\n",
        "\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model_0(x_test)\n",
        "\n",
        "    # 2. caluclate the loss\n",
        "    test_loss = loss_fn(test_pred,y_test)\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | test_loss: {test_loss}\")\n",
        "    # Print our model state_dict\n",
        "    print(model_0.state_dict())\n",
        "\n"
      ],
      "metadata": {
        "id": "kEQRnT5rruWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curve\n",
        "import numpy as np\n",
        "plt.plot(epoch_count,np.array(torch.tensor(loss_values).numpy()),label=\"Train loss\")   # loss values is stored in tensor form by default, to convert it to numpy we use - np.array(torch.tensor(loss_values).numpy())\n",
        "plt.plot(epoch_count,test_loss_values,label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "XxxeSuHn-Ax-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(x_test)"
      ],
      "metadata": {
        "id": "PgIiZA2bvceB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "gEBJMvQ-9CMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "id": "FLE2IjF-9CnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ],
      "metadata": {
        "id": "Y19QzYqa11VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving a model in PyTorch\n",
        "\n",
        "There are three main methods we should know about for saving and loading models in PyTorch.\n",
        "\n",
        "1. `torch.save()` - allows us to save a PyTorch object in python's pickle format\n",
        "2. `torch.load()` - allows us to load a saved PyTorch object.\n",
        "3. `torch.nn.Module.load_state_dict()` - allows us to load a model's saved state dictionary."
      ],
      "metadata": {
        "id": "nTRFASyE3iP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our pytorch model\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Create models directory\n",
        "MODEL_PATH = Path(\"/content/drive/MyDrive/pytorch/models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "\n",
        "# pth - pytorch extension\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# for saving full model -> torch.save(model,PATH)\n",
        "# torch.save(MODEL_NAME, MODEL_SAVE_PATH)\n",
        "\n",
        "# Save the model state_dict()\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "6NsRVCn-A6gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -l (long) to display detailed info...\n",
        "!ls -l /content/drive/MyDrive/pytorch/models/\n",
        "\n",
        "\n",
        "# import os\n",
        "# os.listdir(\"/content/drive/MyDrive/pytorch/models/\")"
      ],
      "metadata": {
        "id": "7aPKPBvVBq1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a PyTorch model\n",
        "\n",
        "Since we've saved our model's `state_dict()` rather than the entire model, we'll create a new instance of our model class and load the saved `state_dict()` into that"
      ],
      "metadata": {
        "id": "Q699hcWuGXXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "PgtYhGreHIqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load a saved state_dict we have to instantiate a new instance of our model class\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
        "\n",
        "loaded_model_0.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "# torch.load(\"/content/drive/MyDrive/pytorch/models/01_pytorch_workflow_model_0.pth\")"
      ],
      "metadata": {
        "id": "Q2-INUOdHMK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "id": "JPNLqBV5HwHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our loaded model\n",
        "\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(x_test)\n",
        "\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "id": "H_Ms1EswIGhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some preds with origianl model\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(x_test)\n",
        "y_preds"
      ],
      "metadata": {
        "id": "OrVm9mGWIdEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare loaded model preds with original model preds\n",
        "y_preds == loaded_model_preds"
      ],
      "metadata": {
        "id": "4ier-JM-IaUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Putting it all together\n",
        "Let's go back through the above and see it all in one place"
      ],
      "metadata": {
        "id": "2p8k6zvtI0SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING PyTorch and matplotlib\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "Rm4NqU1SJmu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create device-agnostic code.\n",
        "\n",
        "This means if we've got access to a GPU, our code will use it (for faster computing)\n",
        "\n",
        "If no GPU is available, the code will default to using CPU."
      ],
      "metadata": {
        "id": "Z_B83oF-J-lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "6F3fP2s_LDv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Data"
      ],
      "metadata": {
        "id": "rHADpkfGJg47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create some data using linear regression formula of y = weight * x + bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create range values\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y (features and labels)\n",
        "x = torch.arange(start,end,step).unsqueeze(dim=1) # without unsqueeze, errors will pop up\n",
        "y = weight*x+bias\n",
        "x[:10], y[:10]"
      ],
      "metadata": {
        "id": "n0NmncB-JkCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_split = int(0.8*len(x))\n",
        "x_train,y_train = x[:train_split],y[:train_split]\n",
        "x_test,y_test = x[train_split:],y[train_split:]\n",
        "len(x_train),len(y_train),len(x_test),len(y_test)"
      ],
      "metadata": {
        "id": "lztGOY23OzTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data\n",
        "plot_predictions(x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "J7g8EkRiRMPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear model by subclassing nn.Module\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Use nn.Linear() for creating the model parameters / also called: linear transform, probing layer, fully connected layer,dense layer\n",
        "    self.linear_layer = nn.Linear(in_features=1,\n",
        "                                  out_features=1) # One infeature to out... one x feature for one y feature\n",
        "\n",
        "  def forward(self,x : torch.Tensor) -> torch.Tensor:  # x should be a torch.Tensor and returns torch.Tensor\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "# Set manual seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "id": "BnI9FSs8T-vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model current device\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "tqjtLSLCZZzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to use the target device (GPU)\n",
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "BsYL5MVsV1qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "QwE-lnxgaSgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "For training we need:\n",
        "* Loss function\n",
        "* Optimizer\n",
        "* Training loop\n",
        "* Testing loop\n"
      ],
      "metadata": {
        "id": "r54iLP_XZozP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function\n",
        "loss_fn = nn.L1Loss() # Same as MAE\n",
        "\n",
        "# Setup our optimizer\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.01)\n"
      ],
      "metadata": {
        "id": "KdNQwfW2aQQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write a training loop\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "# Put data on the target device (device agnostic code for data)\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_1(x_train)\n",
        "\n",
        "  # 2. Calculate loss\n",
        "  loss = loss_fn(y_pred,y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad -> to prevent accumulation of gradients, which might lead to incorrect predictions.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropogation\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(x_test)\n",
        "    test_loss = loss_fn(test_pred,y_test)\n",
        "\n",
        "  # Print out what's happing\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | test_loss: {test_loss}\")\n"
      ],
      "metadata": {
        "id": "Lvtn_BNsbwGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "vDmuXXDvgSG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "id": "0zwi3E57gZm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making and evaluating predictions"
      ],
      "metadata": {
        "id": "lCip-NSUglZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn model into evaluation mode\n",
        "model_1.eval()\n",
        "\n",
        "# Make predictions on the test data\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_1(x_test)\n",
        "y_preds"
      ],
      "metadata": {
        "id": "KUvURtUyglWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model predictions visually\n",
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "id": "WoadNR16b2i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UzQeSiVxjAoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}